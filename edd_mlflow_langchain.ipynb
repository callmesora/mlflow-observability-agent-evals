{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1921ef3",
   "metadata": {},
   "source": [
    "# Eval Driven Development with MLflow & LangChain\n",
    "\n",
    "This notebook demonstrates how to perform **Evaluation Driven Development (EDD)** for GenAI applications using **MLflow 3.0+** and **LangChain**.\n",
    "\n",
    "We will cover two main scenarios:\n",
    "1.  **RAG Evaluation**: Using built-in LLM judges (`RetrievalGroundedness`, `RetrievalRelevance`, etc.) to evaluate a retrieval system.\n",
    "2.  **Agent Evaluation**: Using custom scorers to inspect execution traces and validate tool usage trajectories.\n",
    "\n",
    "### Prerequisites\n",
    "Ensure you have set your `OPENAI_API_KEY` in the environment or a `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07a7f048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if running in Colab or a fresh environment\n",
    "#%pip install -q \"mlflow>=2.14\" langgraph langchain langchain-openai langchain-community langchain-text-splitters faiss-cpu pandas openai python-dotenv bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbd8d61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow version: 3.6.0\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "print(f\"MLflow version: {mlflow.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0f973e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/mlflow/tracking/_tracking_service/utils.py:140: FutureWarning: Filesystem tracking backend (e.g., './mlruns') is deprecated. Please switch to a database backend (e.g., 'sqlite:///mlflow.db'). For feedback, see: https://github.com/mlflow/mlflow/issues/18534\n",
      "  return FileStore(store_uri, store_uri)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/pedro.azevedo/dspt-mlflow/mlruns/413835162552422093', creation_time=1763905836235, experiment_id='413835162552422093', last_update_time=1763905836235, lifecycle_stage='active', name='GenAI_Eval_Demo', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API Key\n",
    "load_dotenv()\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = input(\"Enter your OpenAI API Key: \")\n",
    "\n",
    "# Set a specific experiment for this notebook\n",
    "mlflow.set_experiment(\"GenAI_Eval_Demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6231a17c",
   "metadata": {},
   "source": [
    "## Setup RAG Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f458fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "docs = [\n",
    "        Document(page_content=\"Paul Graham grew up writing short stories and programming on an IBM 1401.\"),\n",
    "        Document(page_content=\"After Y Combinator, Paul Graham spent time painting and working on Lisp.\"),\n",
    "        Document(page_content=\"Paul Graham co-founded Y Combinator, one of the most successful startup accelerators.\"),\n",
    "        Document(page_content=\"Paul Graham wrote influential essays about startups, programming, and technology.\"),\n",
    "        Document(page_content=\"Before Y Combinator, Paul Graham worked on Viaweb, which was later sold to Yahoo.\"),\n",
    "    ]\n",
    "# Create Vector Store & Retriever\n",
    "vectorstore = FAISS.from_documents(docs, OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71c79d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "model = init_chat_model(\"gpt-4.1\")\n",
    "\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve_context(query: str):\n",
    "    \"\"\"Retrieve information to help answer a query.\"\"\"\n",
    "    retrieved_docs = vectorstore.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tools = [retrieve_context]\n",
    "# If desired, specify custom instructions\n",
    "prompt = (\n",
    "    \"You have access to a tool that retrieves context from a blog post. \"\n",
    "    \"Use the tool to help answer user queries.\"\n",
    ")\n",
    "agent = create_agent(model, tools, system_prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dccd3e",
   "metadata": {},
   "source": [
    "## Setup Predict Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "392b2f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_precict_fn(query: str) -> str:\n",
    "    response = agent.invoke({\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": query}],\n",
    "    })\n",
    "    answer = response['messages'][-1].content\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26587c6",
   "metadata": {},
   "source": [
    "## Part 1: RAG Evaluation\n",
    "\n",
    "We will build a simple RAG chain that answers questions about software tools. We will then evaluate it using MLflow's **\"Trace Required\"** judges, which inspect the actual retrieved documents to ensure relevance and groundedness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6fc73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.genai.scorers import (\n",
    "    Correctness,\n",
    "    RelevanceToQuery,\n",
    "    Guidelines,\n",
    ")\n",
    "from mlflow.entities import Feedback, SpanType, Trace\n",
    "from mlflow.genai import scorer\n",
    "from deepeval.metrics import TaskCompletionMetric\n",
    "from deepeval.test_case import LLMTestCase, ToolCall\n",
    "import json\n",
    "from deepeval.metrics import ContextualRelevancyMetric\n",
    "\n",
    "\n",
    "# 1. Enable Autologging\n",
    "mlflow.langchain.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd5ba0e",
   "metadata": {},
   "source": [
    "## Setup RAG Eval Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f345d116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG evaluation dataset with questions closely related to the provided docs\n",
    "# Updated to include task completion and tool trajectory expectations\n",
    "rag_eval_dataset = [\n",
    "    # Childhood and early interests\n",
    "    {\n",
    "        \"inputs\": {\"query\": \"What did Paul Graham do when he was young?\"},\n",
    "        \"expectations\": {\n",
    "            \"expected_response\": \"Paul Graham grew up writing short stories and programming on an IBM 1401.\",\n",
    "            \"expected_facts\": [\"writing short stories\", \"programming on an IBM 1401\"],\n",
    "            \"task_completion_threshold\": 0.8,\n",
    "            \"tool_call_trajectory\": [\"retrieve_context\"],  # Expected tools for simple factual query\n",
    "            \"expected_tools\": [\"retrieve_context\"],\n",
    "        }\n",
    "    },\n",
    "    # Activities after Y Combinator\n",
    "    {\n",
    "        \"inputs\": {\"query\": \"What did Paul Graham pursue after leaving Y Combinator?\"},\n",
    "        \"expectations\": {\n",
    "            \"expected_response\": \"After Y Combinator, Paul Graham spent time painting and working on Lisp.\",\n",
    "            \"expected_facts\": [\"painting\", \"working on Lisp\"],\n",
    "            \"task_completion_threshold\": 0.8,\n",
    "            \"tool_call_trajectory\": [\"retrieve_context\"],\n",
    "            \"expected_tools\": [\"retrieve_context\"],\n",
    "        }\n",
    "    },\n",
    "    # Startup accelerator founding\n",
    "    {\n",
    "        \"inputs\": {\"query\": \"Who co-founded Y Combinator and what is its significance?\"},\n",
    "        \"expectations\": {\n",
    "            \"expected_response\": \"Paul Graham co-founded Y Combinator, one of the most successful startup accelerators.\",\n",
    "            \"expected_facts\": [\"Paul Graham co-founded Y Combinator\", \"successful startup accelerator\"],\n",
    "            \"task_completion_threshold\": 0.7,\n",
    "            \"tool_call_trajectory\": [\"retrieve_context\"],\n",
    "            \"expected_tools\": [\"retrieve_context\"],\n",
    "        }\n",
    "    },\n",
    "    # Essays and writing\n",
    "    {\n",
    "        \"inputs\": {\"query\": \"What topics did Paul Graham write essays about?\"},\n",
    "        \"expectations\": {\n",
    "            \"expected_response\": \"Paul Graham wrote influential essays about startups, programming, and technology.\",\n",
    "            \"expected_facts\": [\"startups\", \"programming\", \"technology\"],\n",
    "            \"task_completion_threshold\": 0.8,\n",
    "            \"tool_call_trajectory\": [\"retrieve_context\"],\n",
    "            \"expected_tools\": [\"retrieve_context\"],\n",
    "        }\n",
    "    },\n",
    "    # Complex multi-step query\n",
    "    {\n",
    "        \"inputs\": {\"query\": \"Compare Paul Graham's work before and after Y Combinator, including his early career and later pursuits\"},\n",
    "        \"expectations\": {\n",
    "            \"expected_response\": \"Before Y Combinator, Paul Graham worked on Viaweb which was sold to Yahoo, and grew up programming on IBM 1401. After Y Combinator, he spent time painting and working on Lisp while writing influential essays.\",\n",
    "            \"expected_facts\": [\"Viaweb\", \"sold to Yahoo\", \"painting\", \"working on Lisp\", \"writing essays\"],\n",
    "            \"task_completion_threshold\": 0.6,  # Lower threshold for complex task\n",
    "            \"tool_call_trajectory\": [\"retrieve_context\", \"retrieve_context\"],  # May involve multiple retrieval calls\n",
    "            \"expected_tools\": [\"retrieve_context\"],\n",
    "        }\n",
    "    },\n",
    "    # Early career and Viaweb\n",
    "    {\n",
    "        \"inputs\": {\"query\": \"What company did Paul Graham work on before Y Combinator and what happened to it?\"},\n",
    "        \"expectations\": {\n",
    "            \"expected_response\": \"Before Y Combinator, Paul Graham worked on Viaweb, which was later sold to Yahoo.\",\n",
    "            \"expected_facts\": [\"Viaweb\", \"sold to Yahoo\"],\n",
    "            \"task_completion_threshold\": 0.8,\n",
    "            \"tool_call_trajectory\": [\"retrieve_context\",\"retrieve_context\"],\n",
    "            \"expected_tools\": [\"retrieve_context\"],\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839c6630",
   "metadata": {},
   "source": [
    "### Helper Functions to Process Traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676de61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_source_nodes(json_input):\n",
    "    \"\"\"\n",
    "    Parses a JSON string containing a message history and extracts source nodes\n",
    "    from tool artifacts.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parsed_data = json.loads(json_input)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing JSON: {e}\")\n",
    "        return []\n",
    "\n",
    "    # Handle the structure: {\"messages\": [...]}\n",
    "    messages = parsed_data.get(\"messages\", []) if isinstance(parsed_data, dict) else []\n",
    "    \n",
    "    source_nodes = []\n",
    "    \n",
    "    for message in messages:\n",
    "        # We are looking for messages where type is 'tool' and an 'artifact' list exists\n",
    "        if message.get(\"type\") == \"tool\" and \"artifact\" in message:\n",
    "            artifacts = message[\"artifact\"]\n",
    "            \n",
    "            # Ensure artifact is a list before extending our results\n",
    "            if isinstance(artifacts, list):\n",
    "                source_nodes.extend(artifacts)\n",
    "                \n",
    "    return source_nodes\n",
    "\n",
    "def extract_final_response(json_input):\n",
    "    \"\"\"\n",
    "    Parses a JSON string and extracts the content of the final AI response.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parsed_data = json.loads(json_input)\n",
    "    except json.JSONDecodeError:\n",
    "        return None\n",
    "\n",
    "    messages = parsed_data.get(\"messages\", []) if isinstance(parsed_data, dict) else []\n",
    "    \n",
    "    # Iterate backwards to find the most recent AI message with content\n",
    "    for message in reversed(messages):\n",
    "        if message.get(\"type\") == \"ai\" and message.get(\"content\"):\n",
    "            return message[\"content\"]\n",
    "            \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3224197f",
   "metadata": {},
   "source": [
    "## Setup Scorers and Evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8d598745",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@scorer(name=\"Task Completeness\")\n",
    "def task_completion_with_deepeval(trace: Trace, inputs: dict, outputs: str, expectations: dict) -> Feedback:\n",
    "    \"\"\"\n",
    "    Custom scorer that uses DeepEval's TaskCompletionMetric to evaluate task completion\n",
    "    based on trace analysis and tool calls\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Extract tool call information from the trace\n",
    "        tool_call_spans = trace.search_spans(span_type=SpanType.TOOL)\n",
    "\n",
    "        # Convert MLflow trace tool calls to DeepEval ToolCall format\n",
    "        tools_called = []\n",
    "        for span in tool_call_spans:\n",
    "            tool_call = ToolCall(\n",
    "                name=span.name,\n",
    "                description=span.attributes.get(\"description\", f\"Tool call for {span.name}\"),\n",
    "                input_parameters=span.inputs or {},\n",
    "                output=span.outputs or []\n",
    "            )\n",
    "            tools_called.append(tool_call)\n",
    "\n",
    "        # Extract the actual response text from the complex output structure\n",
    "        if isinstance(outputs, dict):\n",
    "            # Handle complex response structure\n",
    "            if 'response' in outputs and 'blocks' in outputs['response']:\n",
    "                actual_output = outputs['response']['blocks'][0]['text']\n",
    "            elif 'response' in outputs and isinstance(outputs['response'], str):\n",
    "                actual_output = outputs['response']\n",
    "            else:\n",
    "                actual_output = str(outputs)\n",
    "        elif isinstance(outputs, str):\n",
    "            actual_output = outputs\n",
    "        else:\n",
    "            actual_output = str(outputs)\n",
    "\n",
    "        # Create DeepEval test case\n",
    "        test_case = LLMTestCase(\n",
    "            input=inputs.get(\"query\", \"\"),\n",
    "            actual_output=actual_output,\n",
    "            tools_called=tools_called\n",
    "        )\n",
    "\n",
    "        # Initialize TaskCompletionMetric\n",
    "        threshold = expectations.get(\"task_completion_threshold\", 0.7)\n",
    "        metric = TaskCompletionMetric(\n",
    "            threshold=threshold,\n",
    "            model=\"gpt-4o\",  # Use consistent model\n",
    "            include_reason=True\n",
    "        )\n",
    "\n",
    "        # Run the metric evaluation\n",
    "        metric.measure(test_case)\n",
    "\n",
    "        # Extract results\n",
    "        score = metric.score\n",
    "        reason = metric.reason\n",
    "\n",
    "        return Feedback(\n",
    "            value=score,\n",
    "            rationale=f\"Task completion score: {score:.2f} (threshold: {threshold}). Tools used: {len(tools_called)}. {reason}\",\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        return Feedback(\n",
    "            value=0.0,\n",
    "            rationale=f\"Error evaluating task completion: {str(e)}\",\n",
    "            error=e\n",
    "        )\n",
    "\n",
    "\n",
    "@scorer(name=\"Tool Trajectory\")\n",
    "def tool_call_trajectory_analysis(trace: Trace, expectations: dict) -> Feedback:\n",
    "    \"\"\"\n",
    "    Analyze the tool call trajectory against expected sequence\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Search for tool call spans in the trace\n",
    "        tool_call_spans = trace.search_spans(span_type=SpanType.TOOL)\n",
    "\n",
    "        # Extract actual trajectory\n",
    "        actual_trajectory = [span.name for span in tool_call_spans]\n",
    "        expected_trajectory = expectations.get(\"tool_call_trajectory\", [])\n",
    "\n",
    "        # Calculate trajectory match\n",
    "        trajectory_match = actual_trajectory == expected_trajectory\n",
    "\n",
    "        # Calculate partial match score\n",
    "        if not expected_trajectory:\n",
    "            partial_score = 1.0 if actual_trajectory else 0.0\n",
    "        else:\n",
    "            # Calculate sequence similarity\n",
    "            min_len = min(len(actual_trajectory), len(expected_trajectory))\n",
    "            max_len = max(len(actual_trajectory), len(expected_trajectory))\n",
    "            if max_len == 0:\n",
    "                partial_score = 1.0\n",
    "            else:\n",
    "                matches = sum(1 for i in range(min_len)\n",
    "                             if i < len(actual_trajectory) and i < len(expected_trajectory)\n",
    "                             and actual_trajectory[i] == expected_trajectory[i])\n",
    "                partial_score = matches / max_len\n",
    "\n",
    "        return Feedback(\n",
    "            value=partial_score,\n",
    "            rationale=(\n",
    "                f\"Tool trajectory {'matches' if trajectory_match else 'differs from'} expectations. \"\n",
    "                f\"Expected: {expected_trajectory}. Actual: {actual_trajectory}. \"\n",
    "                f\"Match score: {partial_score:.2f}\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        return Feedback(\n",
    "            value=0.0,\n",
    "            rationale=f\"Error analyzing tool trajectory: {str(e)}\",\n",
    "            error=e\n",
    "        )\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def _extract_deepeval_components(trace : Trace):\n",
    "    \"\"\"Extract input, output, and context from trace data\"\"\"\n",
    "    request = str(trace.data.request)\n",
    "    response = str(trace.data.response)\n",
    "\n",
    "    # extract source nodes if they exist\n",
    "    # Extract Source Nodes\n",
    "    outputs = extract_source_nodes(response)\n",
    "    retrieval_context = [node['page_content'] for node in outputs]\n",
    "    \n",
    "    \n",
    "    actual_output = extract_final_response(response)\n",
    "\n",
    "    return {\n",
    "        'input': request,\n",
    "        'actual_output': actual_output,\n",
    "        'retrieval_context': retrieval_context\n",
    "    }\n",
    "\n",
    "\n",
    "@scorer(name=\"Context Relevancy\")\n",
    "def contextual_relevancy(trace: Trace):\n",
    "    \"\"\"Evaluate RAG traces using DeepEval metrics\"\"\"\n",
    "    \n",
    "    data = _extract_deepeval_components(trace)\n",
    "\n",
    "    # Define DeepEval metrics   \n",
    "    \n",
    "\n",
    "    # Create test cases\n",
    "    test_case= LLMTestCase(\n",
    "            input=data['input'],\n",
    "            actual_output=data['actual_output'],\n",
    "            retrieval_context=data['retrieval_context']\n",
    "        )\n",
    "    \n",
    "    relevancy_metric = ContextualRelevancyMetric(threshold=0.7, model=\"gpt-4o-mini\",\n",
    "                                        include_reason=True)        \n",
    "        \n",
    "    # Run the metric evaluation\n",
    "    relevancy_metric.measure(test_case)\n",
    "\n",
    "    # Extract results\n",
    "    score = relevancy_metric.score\n",
    "    reason = relevancy_metric.reason\n",
    "\n",
    "    return Feedback(\n",
    "        value=score,\n",
    "        rationale=reason,\n",
    "    )\n",
    "\n",
    "# Business-specific guidelines\n",
    "business_guidelines = Guidelines(\n",
    "    name=\"toxicity_clear\",\n",
    "    guidelines=\"\"\"\n",
    "    The response should avoid toxic language and adhere to community guidelines.\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "# Configure RAG-specific scorers\n",
    "retrieval_scorers = [\n",
    "    Correctness(\n",
    "       # model=\"litellm_proxy:/amazon.nova-micro-v1:0\",\n",
    "    ),\n",
    "    RelevanceToQuery(\n",
    "        name=\"AnswerRelevance\"\n",
    "        #model=\"litellm_proxy:/amazon.nova-micro-v1:0\",\n",
    "    ),\n",
    "    contextual_relevancy,\n",
    "]\n",
    "\n",
    "agent_scorers = [\n",
    "    task_completion_with_deepeval,\n",
    "    tool_call_trajectory_analysis,\n",
    "]\n",
    "\n",
    "all_scorers= retrieval_scorers + agent_scorers +[\n",
    "    business_guidelines, \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "086d0e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/23 18:06:47 INFO mlflow.genai.utils.data_validation: Testing model prediction with the first sample in the dataset. To disable this check, set the MLFLOW_GENAI_EVAL_SKIP_TRACE_VALIDATION environment variable to True.\n",
      "2025/11/23 18:06:47 WARNING mlflow.tracing.fluent: Failed to start span LangGraph: 'NonRecordingSpan' object has no attribute 'context'. For full traceback, set logging level to debug.\n",
      "Evaluating:   0%|          | 0/6 [Elapsed: 00:00, Remaining: ?] "
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  17%|█▋        | 1/6 [Elapsed: 00:06, Remaining: 00:30] "
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for Jupyter support\n",
      "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
      "/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for Jupyter support\n",
      "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for Jupyter support\n",
      "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for Jupyter support\n",
      "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  33%|███▎      | 2/6 [Elapsed: 00:08, Remaining: 00:16] "
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  50%|█████     | 3/6 [Elapsed: 00:08, Remaining: 00:08] "
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  67%|██████▋   | 4/6 [Elapsed: 00:08, Remaining: 00:04] "
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  83%|████████▎ | 5/6 [Elapsed: 00:09, Remaining: 00:01] "
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/pedro.azevedo/dspt-mlflow/.venv/lib/python3.13/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 6/6 [Elapsed: 00:12, Remaining: 00:00] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✨ Evaluation completed.\n",
      "\n",
      "Metrics and evaluation results are logged to the MLflow run:\n",
      "  Run name: \u001b[94mSimple Langgraph Agent\u001b[0m\n",
      "  Run ID: \u001b[94m4e35361c32984e39b6cb4020dd747698\u001b[0m\n",
      "\n",
      "To view the detailed evaluation results with sample-wise scores,\n",
      "open the \u001b[93m\u001b[1mTraces\u001b[0m tab in the Run page in the MLflow UI.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "with mlflow.start_run(run_name=\"Simple Langgraph Agent\"):\n",
    "\n",
    "    eval_results = mlflow.genai.evaluate(\n",
    "        data=rag_eval_dataset,\n",
    "        predict_fn=qa_precict_fn,\n",
    "        scorers=all_scorers,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "dd922c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Tool Trajectory/mean': np.float64(0.9166666666666666),\n",
       " 'toxicity_clear/mean': np.float64(1.0),\n",
       " 'AnswerRelevance/mean': np.float64(1.0),\n",
       " 'correctness/mean': np.float64(0.8333333333333334),\n",
       " 'Task Completeness/mean': np.float64(0.8916666666666667),\n",
       " 'Context Relevancy/mean': np.float64(0.4583333333333333)}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aa00cf",
   "metadata": {},
   "source": [
    "## Part 2: Agent Evaluation\n",
    "\n",
    "Now we evaluate a \"DevOps Agent\" that has tools to check server status and restart servers. We want to ensure:\n",
    "1.  **Trajectory**: It checks status *before* restarting (SOP compliance).\n",
    "2.  **Safety**: It never attempts to restart 'prod' without safety checks (simulated here by a hard fail if it tries)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-eval-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
